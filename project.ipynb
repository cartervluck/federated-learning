{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb90bf3-d1dc-4a45-811c-cd8a983b25c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import numpy as np\n",
    "import torch.utils.tensorboard as tb\n",
    "import datetime\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d26aff-2c32-4896-9df1-10b6bbb7a2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "559fa08f-397b-4b85-8425-1ccccbeb9dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.ConvertImageDtype()\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10('./data/torch/cifar', download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b29fcba-6189-4ca5-976d-369c35e7eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(dataset))\n",
    "valid_size = int(0.2 * len(dataset))\n",
    "train_set, valid_set, test_set = torch.utils.data.random_split(dataset, [train_size, valid_size, len(dataset) - train_size - valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b8de8ee-5f66-44c7-b08b-f00c40450ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_mean = (0.4914, 0.4822, 0.4465)\n",
    "cifar_std = (0.2470, 0.2435, 0.2616)\n",
    "\n",
    "normalize = transforms.Normalize(cifar_mean, cifar_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3867083-b82a-4b6f-814f-0bb88e5f45ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, arch=[],padding=True):\n",
    "        super().__init__()\n",
    "        pad = 'same' if padding else 0\n",
    "        size = 32\n",
    "        layers = [nn.Conv2d(3,arch[0][1],arch[0][0], padding=pad)]\n",
    "        if not padding: size -= arch[0][0] - 1\n",
    "        for i in range(len(arch)-1):\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Conv2d(arch[i][1], arch[i+1][1], arch[i+1][0],padding=pad))\n",
    "            if not padding: size -= arch[i+1][0] - 1\n",
    "        layers.append(nn.AvgPool2d(kernel_size=(int(size),int(size))))\n",
    "        layers.append(nn.Flatten())\n",
    "        layers.append(nn.Linear(arch[-1][1],10))\n",
    "        self.layers = layers\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5429717b-7411-4dbb-b979-34569b74c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(arch=[], lr=1e-3, epochs=10, batch_size=64, momentum=0.9,padding=True):\n",
    "\n",
    "    user_data_size = int(0.1 * len(dataset)) # Each user's model is trained on a much smaller, personal dataset\n",
    "    train_cut, _ = torch.utils.data.random_split(train_set, [user_data_size, len(train_set) - user_data_size])\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_cut, shuffle=True, batch_size=batch_size)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_set, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "    network = CNN(arch=arch,padding=padding)\n",
    "    opt = optim.SGD(network.parameters(), lr=lr, momentum=momentum)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Build a name for each training run. In this case, the name has the format\n",
    "    # input_size:hidden1_size:...:hiddenN_size-lr-XX-bs-XX-mom-XX\n",
    "    # The first set of colon-separated integers encodes the MLP architecture while\n",
    "    # lr, bs, and mom, capture the learning rate, batch size, and momentum respectively.\n",
    "\n",
    "    train_accs = []\n",
    "    valid_accs = []\n",
    "\n",
    "    for i in tqdm(range(epochs)):\n",
    "\n",
    "        network.train()\n",
    "        train_acc = []\n",
    "        for batch_xs, batch_ys in train_loader:\n",
    "            batch_xs = batch_xs.to(device)\n",
    "            batch_ys = batch_ys.to(device)\n",
    "            \n",
    "            preds = network(normalize(batch_xs))\n",
    "            acc = (preds.argmax(dim=1) == batch_ys).float().mean()\n",
    "\n",
    "            loss_val = loss(preds, batch_ys)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss_val.backward()\n",
    "            opt.step()\n",
    "\n",
    "        train_accs.append(torch.tensor(train_acc).mean())\n",
    "        \n",
    "\n",
    "        network.eval()\n",
    "        accs = []\n",
    "        losses = []\n",
    "        for batch_xs, batch_ys in valid_loader:\n",
    "            batch_xs = batch_xs.to(device)\n",
    "            batch_ys = batch_ys.to(device)\n",
    "            preds = network(normalize(batch_xs))\n",
    "            accs.append((preds.argmax(dim=1) == batch_ys).float().mean())\n",
    "        acc = torch.tensor(accs).mean()\n",
    "        valid_accs.append(acc)\n",
    "        #print(\"EPOCH \" + str(i) + \": Valid acc \" + acc)\n",
    "        # Log anything you want to track once per epoch here. Note that you do\n",
    "        # not need to increment global_step here.\n",
    "    return (network, valid_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1563123-fa7c-43ad-b6bb-fd3f3963d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_model(network, lr=1e-3, epochs=25, batch_size=64, momentum=0.9,padding=True,model_count=10):\n",
    "    user_data_size = int(len(dataset)/model_count) # Each user's model is trained on a much smaller, personal dataset\n",
    "    train_cut, _ = torch.utils.data.random_split(train_set, [user_data_size, len(train_set) - user_data_size])\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_cut, shuffle=True, batch_size=batch_size)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_set, shuffle=False, batch_size=batch_size)\n",
    "    \n",
    "    opt = optim.SGD(network.parameters(), lr=lr, momentum=momentum)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_accs = []\n",
    "    valid_accs = []\n",
    "\n",
    "    for i in tqdm(range(epochs)):\n",
    "\n",
    "        network.train()\n",
    "        train_acc = []\n",
    "        for batch_xs, batch_ys in train_loader:\n",
    "            batch_xs = batch_xs.to(device)\n",
    "            batch_ys = batch_ys.to(device)\n",
    "            preds = network(normalize(batch_xs))\n",
    "            acc = (preds.argmax(dim=1) == batch_ys).float().mean()\n",
    "\n",
    "            loss_val = loss(preds, batch_ys)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss_val.backward()\n",
    "            opt.step()\n",
    "\n",
    "        train_accs.append(torch.tensor(train_acc).mean())\n",
    "        \n",
    "\n",
    "        network.eval()\n",
    "        accs = []\n",
    "        losses = []\n",
    "        for batch_xs, batch_ys in valid_loader:\n",
    "            batch_xs = batch_xs.to(device)\n",
    "            batch_ys = batch_ys.to(device)\n",
    "            preds = network(normalize(batch_xs))\n",
    "            accs.append((preds.argmax(dim=1) == batch_ys).float().mean())\n",
    "        acc = torch.tensor(accs).mean()\n",
    "        valid_accs.append(acc)\n",
    "        #print(\"EPOCH \" + str(i) + \": Valid acc \" + acc)\n",
    "        # Log anything you want to track once per epoch here. Note that you do\n",
    "        # not need to increment global_step here.\n",
    "    return valid_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acce37de-9a8a-424d-97d6-2a1bde26cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(models,arch,trained_models=[]):\n",
    "    if trained_models == []:\n",
    "        trained_models = models\n",
    "    agg = CNN(arch=arch,padding=False)\n",
    "    agg.to(device)\n",
    "    state_agg = agg.state_dict()\n",
    "    for m in trained_models:\n",
    "        state_m = m.state_dict()\n",
    "        for layer in state_agg:\n",
    "            state_agg[layer] = state_agg[layer] + state_m[layer]\n",
    "\n",
    "    for layer in state_agg:\n",
    "        state_agg[layer] = state_agg[layer] / len(trained_models)\n",
    "\n",
    "    for m in models:\n",
    "        state_m = m.state_dict()\n",
    "        for layer in state_m:\n",
    "            state_m[layer] = state_agg[layer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e57c3c6-e807-4b77-abf6-2eb2b5af806e",
   "metadata": {},
   "source": [
    "Ideas for Decentralized Aggregation:\n",
    "* Layered Masking Aggregation\n",
    "    * Each user generates a random \"masked model\" which is within expected model parameters\n",
    "    * Add together every masked model to generate aggregate masked model (AMM)\n",
    "    * Each user calculates mask = masked model - true model\n",
    "    * Go around removing masks from AMM\n",
    "    * So long as a user can't see both the masked model and the mask, they can't know a user's true model\n",
    "    * Can calculate user i's masked model if user i-1 and i+1 are compromised (where user k adds their masked model and passes it to user k+1)\n",
    "    * Can calculate user i's mask if user i-1 and i+1 are compromised\n",
    "    * No one malicious user can violate security, but still pretty weak.\n",
    "* Just Use MPC\n",
    "    * For a large network or many parties, this gets really expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f458ee4e-bf9b-484f-a81c-174d55f2b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_count = 20\n",
    "arch = [(7, 8), (3, 16), (3, 32), (3, 64)]\n",
    "models = [CNN(arch=arch,padding=False) for i in range(model_count)]\n",
    "for m in models:\n",
    "    m.to(device)\n",
    "accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67333889-7b7f-4a3a-9ef2-1d0c6cebd2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(network,loader):\n",
    "    network.eval()\n",
    "    accs = []\n",
    "    for batch_xs, batch_ys in loader:\n",
    "        batch_xs = batch_xs.to(device)\n",
    "        batch_ys = batch_ys.to(device)\n",
    "        preds = network(normalize(batch_xs))\n",
    "        accs.append((preds.argmax(dim=1) == batch_ys).float().mean())\n",
    "    acc = torch.tensor(accs).mean()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be6997fd-1c0b-46b2-8e5e-1ea4d5b12608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Training model 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2259b1977b84c76ba7db4246ffbb9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3481)\n",
      "Training model 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e778d404604e4c95822112b7b3e0b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3374)\n",
      "Training model 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a0f44a81344a82b74130f3899b498d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3184)\n",
      "Training model 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09462460f08f4b69a16c0518aad6e1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model\u001b[39m\u001b[38;5;124m\"\u001b[39m,i)\n\u001b[1;32m----> 9\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43miterate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-3\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mrounds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m round_accs\u001b[38;5;241m.\u001b[39mappend(acc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(acc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[1;32mIn[8], line 39\u001b[0m, in \u001b[0;36miterate_model\u001b[1;34m(network, lr, epochs, batch_size, momentum, padding, model_count)\u001b[0m\n\u001b[0;32m     37\u001b[0m     batch_xs \u001b[38;5;241m=\u001b[39m batch_xs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     38\u001b[0m     batch_ys \u001b[38;5;241m=\u001b[39m batch_ys\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 39\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_xs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     accs\u001b[38;5;241m.\u001b[39mappend((preds\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m batch_ys)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m     41\u001b[0m acc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(accs)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl-class\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl-class\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl-class\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl-class\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl-class\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl-class\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl-class\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl-class\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl-class\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rounds = 5\n",
    "for r in range(rounds):\n",
    "    print(\"Round\",r+1)\n",
    "    i = 0\n",
    "    round_accs = []\n",
    "    for m in models:\n",
    "        i += 1\n",
    "        print(\"Training model\",i)\n",
    "        acc = iterate_model(m,lr=2e-3 * (rounds - r),model_count=model_count)\n",
    "        round_accs.append(acc[-1])\n",
    "        print(acc[-1])\n",
    "    print(\"Avg. Accuracy:\",np.mean(round_accs))\n",
    "    print(\"Aggregating\")\n",
    "    aggregate(models,arch)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_set, shuffle=False, batch_size=64)\n",
    "    print(\"Aggregate Evaluation Accuracy:\",eval_model(models[0],valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "59cd661b-032d-460b-9aaa-29c8fb596785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19390824\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d6ff2530-0e92-4905-8c5c-9eef344df2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4790)\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_set, shuffle=False, batch_size=64)\n",
    "\n",
    "agg.eval()\n",
    "accs = []\n",
    "losses = []\n",
    "for batch_xs, batch_ys in test_loader:\n",
    "    preds = models[0](normalize(batch_xs))\n",
    "    accs.append((preds.argmax(dim=1) == batch_ys).float().mean())\n",
    "acc = torch.tensor(accs).mean()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6fb388-e946-427a-b03b-8cbc61a96f50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
